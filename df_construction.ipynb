{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pickles Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge crop and trades DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_pivot(raw_df):\n",
    "    '''\n",
    "    Function that pivots the table twice to creating five new columns based on two columns.\n",
    "    '''\n",
    "    # pivot column 'element crops'\n",
    "    df = raw_df.pivot_table(values=['value_crops'],\\\n",
    "                                  index=['area_code', 'area_crops', 'item_code_crops', 'item_crops', 'year', \\\n",
    "                                         'item_trades', 'element_trades', 'value_trades'],\\\n",
    "                                  columns=['element_crops']).reset_index()\n",
    "    \n",
    "    # deal with index to flatten\n",
    "    df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "\n",
    "    # rename columns according to our nomenclature\n",
    "    df.rename(columns= {'value_crops Area harvested': 'area_harvested', 'value_crops Production': 'production',\\\n",
    "                   'value_crops Yield':'yield'}, inplace=True)\n",
    "    \n",
    "    # pivot column 'element trades'\n",
    "    df = df.pivot_table(values=['value_trades'],\\\n",
    "                        index=['area_code', 'area_crops', 'item_code_crops', 'item_crops', 'year', \\\n",
    "                               'item_trades', 'area_harvested', 'production', 'yield'],\\\n",
    "                        columns=['element_trades']).reset_index()\n",
    "        \n",
    "    # deal with index to flatten\n",
    "    df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "    \n",
    "    # rename columns according to our nomenclature\n",
    "    df.rename(columns= {'value_trades Export Quantity': 'export_q', 'value_trades Export Value': 'export_v',\\\n",
    "                   'value_trades Import Quantity':'import_q', 'value_trades Import Value': 'import_v'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_group_crops_df():\n",
    "    #Quickly load the data : \n",
    "    group_crops_df = pd.read_csv('data/GroupCrops.csv')\n",
    "    #Column names to lower case\n",
    "    group_crops_df.columns = map(lambda name : name.lower().replace(' ', '_'), group_crops_df.columns) \n",
    "\n",
    "    # Load the UN Comtrade Commodity Classifications :\n",
    "    UNCCC_df = pd.read_excel('data/UNCCC.xlsx')\n",
    "    # Keep the classification we are interested in (H4)\n",
    "    HS12_df = UNCCC_df[UNCCC_df.Classification=='H4']\n",
    "    \n",
    "    # remove Nan values\n",
    "    group_crops_cleaned_df = group_crops_df[~group_crops_df['hs12_code'].isnull()]\n",
    "    \n",
    "    # If the items is assigned mutliple labels, we only keep the first one\n",
    "    HS12_Code = group_crops_cleaned_df['hs12_code'].str.split(', ',expand=True).loc[:,0]\n",
    "    \n",
    "    group_crops_cleaned_df = pd\\\n",
    "                            .concat([group_crops_cleaned_df,HS12_Code],axis=1)\\\n",
    "                            .drop(['factor','hs_code','hs07_code','cpc_code','hs12_code', \\\n",
    "                                   'item_group_code', 'item_group', 'item'],axis=1)\n",
    "    \n",
    "    group_crops_cleaned_df.rename(columns={0:'hs12_code'},inplace=True)\n",
    "    \n",
    "    # Add parent and child codes\n",
    "    group_crops_cleaned_df['parent_group'] = group_crops_cleaned_df['hs12_code'].str[:2]#.astype(int)\n",
    "    group_crops_cleaned_df['child_group'] = group_crops_cleaned_df['hs12_code'].str[:4]#.astype(int)\n",
    "    \n",
    "    # Add parent description\n",
    "    group_crops_cleaned_df = group_crops_cleaned_df\\\n",
    "                        .merge(HS12_df[['Code', 'Description']], how='inner', left_on='parent_group', right_on='Code')\\\n",
    "                        .drop(['Code'], axis=1)\n",
    "\n",
    "    group_crops_cleaned_df.rename(columns={'Description':'parent_description'}, inplace=True)\n",
    "    \n",
    "    # Add child description\n",
    "    group_crops_cleaned_df = group_crops_cleaned_df\\\n",
    "                        .merge(HS12_df[['Code', 'Description']], how='inner', left_on='child_group', right_on='Code')\\\n",
    "                        .drop(['Code'], axis=1)\n",
    "\n",
    "    group_crops_cleaned_df.rename(columns={'Description':'child_description'}, inplace=True)\n",
    "    \n",
    "    # drop duplicates\n",
    "    group_crops_cleaned_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return group_crops_cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_df() :\n",
    "    \n",
    "    unpickled_df = pd.read_pickle(\"data/big_ass_df.pickle\")\n",
    "    \n",
    "    # clean unpickled_df\n",
    "    unpickled_df = unpickled_df.drop(['element_code_crops','flag','area_trades','element_code_trades'],axis=1)\n",
    "    \n",
    "    # reorganize columns by pivoting twice\n",
    "    items_df = double_pivot(unpickled_df)\n",
    "    \n",
    "    # load group crops df\n",
    "    groups_df = load_group_crops_df()\n",
    "    \n",
    "    # merge both \n",
    "    df_final = items_df.merge(groups_df, how='left', left_on='item_code_crops',right_on='item_code')\\\n",
    "                        .drop(['item_code_crops', 'item_code'], axis=1)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cigars, cheroots', 'Vegetables, preserved nes',\n",
       "       'Vegetables in vinegar', 'Vegetables, dehydrated',\n",
       "       'Vegetables, frozen', 'Vegetables, temporarily preserved',\n",
       "       'Oil, vegetable origin nes',\n",
       "       'Vegetables, homogenized preparations',\n",
       "       'Vegetables, preserved, frozen', 'Waxes vegetable',\n",
       "       'Feed, vegetable products nes',\n",
       "       'Leeks, other alliaceous vegetables', 'Cereals, breakfast',\n",
       "       'Flour, cereals', 'Juice, citrus, concentrated',\n",
       "       'Juice, citrus, single strength', 'Flax fibre and tow',\n",
       "       'Flax fibre raw', 'Oil, boiled etc', 'Oil, essential nes',\n",
       "       'Oils, fats of animal nes', 'Oil, citronella',\n",
       "       'Hair, goat, coarse', 'Pyrethrum, dried', 'Pyrethrum, extraction',\n",
       "       'Peppermint'], dtype=object)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All items which don't have any child or parents matching (as we have done  a left join)\n",
    "final_df[final_df.child_group.isnull()].item_trades.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Wheat and meslin', 'Barley', 'Maize (corn)', 'Rye', 'Oats',\n",
       "       'Rice', 'Buckwheat, millet and canary seeds; other cereals',\n",
       "       'Grain sorghum'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df.parent_group=='10'].child_description.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_pickle('data/final_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_group_code</th>\n",
       "      <th>country_group</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "      <th>m49_code</th>\n",
       "      <th>iso2_code</th>\n",
       "      <th>iso3_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>4</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>12</td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>7</td>\n",
       "      <td>Angola</td>\n",
       "      <td>24</td>\n",
       "      <td>AO</td>\n",
       "      <td>AGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>53</td>\n",
       "      <td>Benin</td>\n",
       "      <td>204</td>\n",
       "      <td>BJ</td>\n",
       "      <td>BEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>Botswana</td>\n",
       "      <td>72</td>\n",
       "      <td>BW</td>\n",
       "      <td>BWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "      <td>233</td>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>854</td>\n",
       "      <td>BF</td>\n",
       "      <td>BFA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_group_code country_group  country_code       country  m49_code  \\\n",
       "0                5100        Africa             4       Algeria        12   \n",
       "1                5100        Africa             7        Angola        24   \n",
       "2                5100        Africa            53         Benin       204   \n",
       "3                5100        Africa            20      Botswana        72   \n",
       "4                5100        Africa           233  Burkina Faso       854   \n",
       "\n",
       "  iso2_code iso3_code  \n",
       "0        DZ       DZA  \n",
       "1        AO       AGO  \n",
       "2        BJ       BEN  \n",
       "3        BW       BWA  \n",
       "4        BF       BFA  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_country = pd.read_csv('Data/GroupsCountry.csv')\n",
    "df_country.columns = map(lambda name : name.lower().replace(' ', '_'), df_country.columns) #Column names to lower case\n",
    "df_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionnary that regroup all the countries in one country group\n",
    "dicts = {}\n",
    "list_group = df_country['country_group_code'].unique()\n",
    "keys = list_group\n",
    "for i in range(len(list_group)):\n",
    "    dicts[list_group[i]]= df_country[df_country['country_group_code']==list_group[i]]['country_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionnary for name + subregions\n",
    "dicts_country = {}\n",
    "keys = list_group\n",
    "for i in range(len(list_group)):\n",
    "    dicts_country[list_group[i]] = df_country['country_group'].unique()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5501</td>\n",
       "      <td>Australia and New Zealand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5206</td>\n",
       "      <td>Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5204</td>\n",
       "      <td>Central America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5301</td>\n",
       "      <td>Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5101</td>\n",
       "      <td>Eastern Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5302</td>\n",
       "      <td>Eastern Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5401</td>\n",
       "      <td>Eastern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5706</td>\n",
       "      <td>European Union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5802</td>\n",
       "      <td>Land Locked Developing Countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5801</td>\n",
       "      <td>Least Developed Countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5815</td>\n",
       "      <td>Low Income Food Deficit Countries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                regions\n",
       "5100                             Africa\n",
       "5200                           Americas\n",
       "5300                               Asia\n",
       "5501          Australia and New Zealand\n",
       "5206                          Caribbean\n",
       "5204                    Central America\n",
       "5301                       Central Asia\n",
       "5101                     Eastern Africa\n",
       "5302                       Eastern Asia\n",
       "5401                     Eastern Europe\n",
       "5400                             Europe\n",
       "5706                     European Union\n",
       "5802   Land Locked Developing Countries\n",
       "5801          Least Developed Countries\n",
       "5815  Low Income Food Deficit Countries"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all the suregions and their name\n",
    "pd.DataFrame.from_dict(dicts_country,orient='index',columns=['regions']).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def badassfunction(df_import_export,group_country=None,country=None,group_crops=None,crops=None,year=None,by_crop=False,by_country=False):\n",
    "    \"\"\"\n",
    "    From the original dataset, this function will processed the dataset \n",
    "    to return a summary of the desired crops, country and year\n",
    "    INPUTS : \n",
    "    - df_import_export\n",
    "    - group_country\n",
    "    - country\n",
    "    - group_crops\n",
    "    - year\n",
    "    OUTPUT : \n",
    "    - cleaned df\n",
    "    \"\"\"\n",
    "    df_cleaned = df_import_export\n",
    "    # Extract country\n",
    "    if group_country != None :\n",
    "        df_cleaned = df_cleaned[df_cleaned['area_code'].isin(dicts.get(group_country))]\n",
    "    if country != None:\n",
    "        df_cleaned = df_cleaned[df_cleaned['country_code']==country]\n",
    "    if group_crops != None:\n",
    "        df_cleaned = df_cleaned[df_cleaned['parent_group']==group_crops]\n",
    "    if crops != None:\n",
    "        df_cleaned = df_cleaned[df_cleaned['child_group']==crops]\n",
    "    if year != None: \n",
    "        df_cleaned = df_cleaned[df_cleaned['year']==year]\n",
    "     \n",
    "    # Add new features\n",
    "    df_cleaned['diff_quantity'] = df_cleaned['export_quantity'] - df_cleaned['import_quantity']\n",
    "    df_cleaned['profit'] = df_cleaned['export_value'] - df_cleaned['import_value']\n",
    "\n",
    "    # If feature is added above then add it name in that list\n",
    "    list_features = ['export_quantity','export_value','import_quantity','import_value','diff_quantity','profit']\n",
    "    #Group by item\n",
    "    if by_crop:\n",
    "        df_sum = df_cleaned.groupby(['item_x','parent_group','child_group'])[list_features].sum().reset_index()\n",
    "\n",
    "        df_max = df_cleaned.groupby(['item_x','parent_group','child_group'])[list_features].max().reset_index()   \n",
    "        df_max_index = df_cleaned.groupby(['item_x','parent_group','child_group'])[list_features].idxmax().reset_index()\n",
    "\n",
    "        df_min = df_cleaned.groupby(['item_x','parent_group','child_group'])[list_features].min().reset_index()\n",
    "        df_min_index =  df_cleaned.groupby(['item_x','parent_group','child_group'])[list_features].idxmin().reset_index()\n",
    "    \n",
    "        merge_item = 'item_x'\n",
    "        replace_item = 'area'\n",
    "\n",
    "    if by_country:\n",
    "        df_sum = df_cleaned.groupby(['area','area_code'])[list_features].sum().reset_index()\n",
    "\n",
    "        df_max = df_cleaned.groupby(['area','area_code'])[list_features].max().reset_index()   \n",
    "        df_max_index = df_cleaned.groupby(['area','area_code'])[list_features].idxmax().reset_index()\n",
    "\n",
    "        df_min = df_cleaned.groupby(['area','area_code'])[list_features].min().reset_index()\n",
    "        df_min_index =  df_cleaned.groupby(['area','area_code'])[list_features].idxmin().reset_index()\n",
    "    \n",
    "        merge_item = 'area'\n",
    "        replace_item = 'item_x'\n",
    "    \n",
    "    for i in range(len(list_features)):\n",
    "        df_max_index.loc[:,list_features[i]] = df_import_export.loc[df_max_index.loc[:,list_features[i]],replace_item].values\n",
    "    for i in range(len(list_features)):\n",
    "        df_min_index.loc[:,list_features[i]] = df_import_export.loc[df_min_index.loc[:,list_features[i]],replace_item].values\n",
    "    \n",
    "    # merge max \n",
    "    df_max_merged = pd.merge(df_max.loc[:,[merge_item]+list_features],df_max_index.loc[:,[merge_item]+list_features],left_on=merge_item,right_on=merge_item,how='inner',suffixes=('_max','_max_names'))\n",
    "    # merge min \n",
    "    df_min_merged = pd.merge(df_min.loc[:,[merge_item]+list_features],df_min_index.loc[:,[merge_item]+list_features],left_on=merge_item,right_on=merge_item,how='inner',suffixes=('_min','_min_names'))\n",
    "\n",
    "    # merge total\n",
    "    df_merged_tot = pd.merge(df_min_merged,df_max_merged, left_on=merge_item,right_on=merge_item)\n",
    "    \n",
    "    df_tot = pd.merge(df_sum, df_merged_tot, left_on=merge_item,right_on=merge_item)\n",
    "    return df_tot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
